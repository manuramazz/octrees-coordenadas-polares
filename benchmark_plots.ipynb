{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "BASE_DATA_PATH = os.path.join(\"out\")\n",
    "OUTPUT_FOLDER = os.path.join(\"out\", \"plots_full\")\n",
    "TIMES_IN_MS = False\n",
    "\n",
    "def get_dataset_file(cloud_name, timestamp = \"latest\", data_path = BASE_DATA_PATH):\n",
    "    # Get all CSV files in the folder\n",
    "    csv_folder = os.path.join(data_path, cloud_name)\n",
    "    csv_files = glob.glob(os.path.join(csv_folder, \"*.csv\"))\n",
    "    df = None\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in the folder: {csv_folder}\")\n",
    "    if timestamp == 'latest':\n",
    "        # Parse filenames and find the latest based on the timestamp in the name\n",
    "        file = max(csv_files, key=lambda x: datetime.strptime(\n",
    "            '-'.join(x.split('-')[1:]).replace('.csv', ''),\n",
    "            \"%Y-%m-%d-%H:%M:%S\"\n",
    "        ))\n",
    "        print(f\"Loading latest file: {file}\")\n",
    "        df = pd.read_csv(file)\n",
    "    else:\n",
    "        # Check for exact match with the date_str in the filename (ignoring the prefix)\n",
    "        for file in csv_files:\n",
    "            filename = os.path.basename(file)\n",
    "            file_timestamp = filename.split('-')[1:]  # Split to get timestamp part\n",
    "            file_timestamp = '-'.join(file_timestamp).replace('.csv', '')  # Rebuild timestamp string\n",
    "            if timestamp == file_timestamp:\n",
    "                print(f\"Loading file: {file}\")\n",
    "                df = pd.read_csv(file)\n",
    "        if df is None:\n",
    "               FileNotFoundError(f\"File with date '{timestamp}' not found in folder: {csv_folder}\")\n",
    "    # Convert times to milliseconds\n",
    "    if TIMES_IN_MS:\n",
    "        df['mean'] = df['mean'] * 1000\n",
    "        df['stdev'] = df['stdev'] * 1000#\n",
    "        df['warmup_time'] = df['warmup_time'] * 1000\n",
    "    return df\n",
    "\n",
    "def read_multiple_datasets(clouds_datasets, data_path = BASE_DATA_PATH):\n",
    "    dfs = {}\n",
    "    for cloud, dataset in clouds_datasets.items():\n",
    "        dfs[cloud] = get_dataset_file(cloud, \"latest\", data_path)\n",
    "    return dfs\n",
    "\n",
    "def output_fig(fig, filename, dataset = \"all\", cloud = None):\n",
    "    output_folder = \"\"\n",
    "    if cloud is None:\n",
    "        output_folder = os.path.join(OUTPUT_FOLDER, dataset)\n",
    "    else:\n",
    "        output_folder = os.path.join(OUTPUT_FOLDER, dataset, cloud)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    fig.savefig(os.path.join(output_folder, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',  # Use sans-serif as a fallback\n",
    "    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "    \n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 9,\n",
    "    'axes.titlesize': 11,\n",
    "    'xtick.labelsize': 8,\n",
    "    'ytick.labelsize': 8,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.titlesize': 12,\n",
    "    \n",
    "    'axes.grid': True,\n",
    "    'axes.grid.axis': 'y',  # Only horizontal grid lines\n",
    "    'grid.linestyle': '-',  # Solid line\n",
    "    'grid.linewidth': 0.4,  # Very thin grid lines\n",
    "    'grid.color': '#CCCCCC',  # Light gray grid\n",
    "    \n",
    "    'axes.axisbelow': True,\n",
    "    'figure.figsize': (6, 4),  # Standard publication-friendly figure size\n",
    "    'figure.dpi': 100, # Smaller preview\n",
    "    # 'figure.dpi': 300, \n",
    "    \n",
    "    'lines.linewidth': 1.0,  # Consistent line thickness\n",
    "    'lines.markersize': 4,  # Consistent marker size\n",
    "\n",
    "    'figure.facecolor': 'white',  # Background color of the figure\n",
    "    'figure.edgecolor': 'white',   # Edge color of the figure\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some aux. functions for plot information\n",
    "def add_execution_details(cloud, dataset, searches, repeats, points, fig, h_ex=0.93, h_left = 0.10):\n",
    "    execution_details = [\n",
    "        f\"- {searches:,} searches x {repeats:,} repeats\",\n",
    "        f\"- Point cloud: {cloud} ({points:,} points)\",\n",
    "        f\"- Dataset: {dataset}\",\n",
    "    ]\n",
    "    fig.text(h_left, h_ex,\n",
    "            '\\n'.join(execution_details),\n",
    "            fontfamily='monospace',\n",
    "            color='#505050',\n",
    "            ha='left',\n",
    "            va='top',\n",
    "            linespacing=1.3)\n",
    "    \n",
    "def add_execution_details_multiple_datasets(clouds, searches, repeats, fig, h_ex=0.90):\n",
    "    execution_details = [\n",
    "        f\"- {searches:,} searches x {repeats:,} repeats\",\n",
    "        f\"- {len(clouds)} point clouds\",\n",
    "    ]\n",
    "    fig.text(0.10, h_ex,\n",
    "            '\\n'.join(execution_details),\n",
    "            fontfamily='monospace',\n",
    "            color='#505050',\n",
    "            ha='left',\n",
    "            va='top',\n",
    "            linespacing=1.3)\n",
    "\n",
    "def add_title_subtitle(title, subtitle, fig, h_title=0.98, h_subtitle=0.95):\n",
    "    fig.text(0.10, h_title, \n",
    "            title, \n",
    "            fontsize=16, \n",
    "            fontweight='bold', \n",
    "            ha='left', \n",
    "            va='top')\n",
    "\n",
    "    fig.text(0.10, h_subtitle,\n",
    "            subtitle,\n",
    "            fontsize=12,\n",
    "            fontstyle='italic',\n",
    "            color='#404040',\n",
    "            ha='left',\n",
    "            va='top')\n",
    "\n",
    "def add_octree_types_legend(legend_handles, legend_labels, legend_title, fig):\n",
    "    fig.legend(\n",
    "        legend_handles,\n",
    "        legend_labels,\n",
    "        title=legend_title,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.9, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dicts store information about the type parameters and possible combinations used in each visualization, \n",
    "# along with the palette of colors\n",
    "TYPES_INFO_OCTREE_ENCODER = {\n",
    "    \"type_parameters\":  ['octree', 'encoder'],\n",
    "    \"available_types\": pd.DataFrame({\n",
    "        'octree': ['LinearOctree', 'LinearOctree', 'Octree', 'Octree', 'Octree'],\n",
    "        'encoder': ['HilbertEncoder3D', 'MortonEncoder3D', 'HilbertEncoder3D', 'MortonEncoder3D', 'Unencoded']\n",
    "    }),\n",
    "\n",
    "    \"palette\": {\n",
    "        ('LinearOctree', 'HilbertEncoder3D'): '#1984c5',\n",
    "        ('LinearOctree', 'MortonEncoder3D'): '#63bff0',\n",
    "        ('Octree', 'HilbertEncoder3D'): '#c23728',\n",
    "        ('Octree', 'MortonEncoder3D'): '#de6e56',\n",
    "        ('Octree', 'Unencoded'): '#e1a692'\n",
    "    }\n",
    "}\n",
    "\n",
    "TYPES_INFO_OCTREE_POINT = {\n",
    "    \"type_parameters\":  ['octree', 'point_type'],\n",
    "    \"available_types\": pd.DataFrame({\n",
    "        'octree': ['LinearOctree', 'LinearOctree', 'LinearOctree', 'Octree', 'Octree', 'Octree'],\n",
    "        'point_type': ['Point', 'Lpoint64', 'Lpoint', 'Point', 'Lpoint64', 'Lpoint']\n",
    "    }),\n",
    "    \"palette\": {\n",
    "        ('LinearOctree', 'Point'): '#0f5f87',\n",
    "        ('LinearOctree', 'Lpoint64'): '#1984c5',\n",
    "        ('LinearOctree', 'Lpoint'): '#63bff0',\n",
    "        ('Octree', 'Point'): '#9f1b17',\n",
    "        ('Octree', 'Lpoint64'): '#de6e56',\n",
    "        ('Octree', 'Lpoint'): '#e1a692'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTREE_COMP_DATA_PATH = os.path.join(BASE_DATA_PATH, \"octree_comp_full\")\n",
    "ALGO_COMP_DATA_PATH = os.path.join(BASE_DATA_PATH, \"algo_comp_full\")\n",
    "POINT_COMP_DATA_PATH = os.path.join(BASE_DATA_PATH, \"point_comp_full\")\n",
    "APPROX_SEARCH_DATA_PATH = os.path.join(BASE_DATA_PATH, \"approx_search_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octree_runtime_comparison(cloud, dataset, operations, operation_name, show_warmup_time=False, types_info=TYPES_INFO_OCTREE_ENCODER, data_path=OCTREE_COMP_DATA_PATH):\n",
    "    df = get_dataset_file(cloud, \"latest\", data_path)\n",
    "    # Filter the dataset for the specified operation\n",
    "    operation_df = df[df['operation'].isin(operations)]\n",
    "    # Get unique radii and kernels\n",
    "    radii = sorted(operation_df['radius'].unique())\n",
    "    kernels = operation_df['kernel'].unique()\n",
    "   \n",
    "    # Create subplot grid with reduced vertical spacing\n",
    "    fig, axes = plt.subplots(len(radii), 1, figsize=(12, 5 + 3 * len(radii)),\n",
    "                              gridspec_kw={'hspace': 0.3})\n",
    "    if len(radii) == 1:\n",
    "        axes = [axes]\n",
    "   \n",
    "    # Bar spacing parameters\n",
    "    bar_width = 0.15\n",
    "    group_width = bar_width * len(types_info[\"available_types\"])\n",
    "    group_gap = 0.5\n",
    "   \n",
    "    legend_handles, legend_labels = [], []\n",
    "    # First loop through each radius: 1.0, 2.5, 5.0, ...\n",
    "    for radius_idx, radius in enumerate(radii):\n",
    "        ax = axes[radius_idx]\n",
    "        radius_data = operation_df[operation_df['radius'] == radius]\n",
    "        # Now iterate through kernels: circle, sphere, square, cube, ...\n",
    "        kernel_labels = []\n",
    "        for i, kernel in enumerate(kernels):\n",
    "            kernel_data = radius_data[radius_data['kernel'] == kernel]\n",
    "            if kernel_data.empty:\n",
    "                kernel_labels.append(f'{kernel} kernel\\nNo data available')\n",
    "                continue\n",
    "            avg_total = kernel_data['avg_result_size'].iloc[0]\n",
    "            kernel_labels.append(f'{kernel} kernel\\nAvg. points found: {avg_total:,.0f}')\n",
    "           \n",
    "            # Finally, iterate through each of the octree implementations identified by the (octree, encoder, point_type) tuple\n",
    "            for j, (_, params) in enumerate(types_info[\"available_types\"].iterrows()):\n",
    "                # Extract parameters dynamically from the row\n",
    "                key = tuple(params[col] for col in types_info[\"type_parameters\"])\n",
    "                octree_data = kernel_data[\n",
    "                    (kernel_data[types_info[\"type_parameters\"]] == pd.Series(key, index=types_info[\"type_parameters\"])).all(axis=1)\n",
    "                ]\n",
    "                if octree_data.empty:\n",
    "                    continue\n",
    "                means = octree_data['mean'].values\n",
    "                stdevs = octree_data['stdev'].values\n",
    "                warmup_times = octree_data['warmup_time'].values\n",
    "                x_pos = i * (group_width + group_gap) + j * bar_width\n",
    "                \n",
    "                # Main execution time bar\n",
    "                bar = ax.bar(x_pos, means[0], bar_width,\n",
    "                             color=types_info[\"palette\"][key])\n",
    "                \n",
    "                # Warmup time bar (if enabled)\n",
    "                if show_warmup_time:\n",
    "                    ax.bar(x_pos, warmup_times[0], bar_width, \n",
    "                           color=\"none\", \n",
    "                           edgecolor='black', alpha = 0.5,\n",
    "                           zorder=-2)  # Ensure it's drawn on top\n",
    "                \n",
    "                ax.errorbar(x_pos, means[0], stdevs[0],\n",
    "                            color='gray', capsize=3, capthick=1,\n",
    "                            fmt='none', elinewidth=1)\n",
    "               \n",
    "                formatted_label = \", \".join(f\"{value}\" for param, value in zip(types_info[\"type_parameters\"], key))\n",
    "                if radius_idx == 0 and formatted_label not in legend_labels:\n",
    "                    legend_handles.append(bar)\n",
    "                    legend_labels.append(formatted_label)\n",
    "        \n",
    "        # Set kernel labels\n",
    "        kernel_group_centers = [i * (group_width + group_gap) + group_width/2 for i in range(len(kernels))]\n",
    "        ax.set_xticks(kernel_group_centers)\n",
    "        ax.set_xticklabels(kernel_labels)\n",
    "       \n",
    "        ax.text(0.04, 0.96, f'Radius = {radius}',\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=12, fontweight='bold',\n",
    "                va='top', ha='left')\n",
    "       \n",
    "        ax.set_ylabel(f\"Execution time {'(ms)' if TIMES_IN_MS else '(seconds)'}\")\n",
    "   \n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Octree type\", fig)\n",
    "    add_title_subtitle(f\"{operation_name} performance analysis\", \n",
    "                       f\"Analysis of octree type over multiple search radii and kernels{' with warmup times' if show_warmup_time else ''}\", \n",
    "                       fig)\n",
    "    # The number of searches, repeats and points in the dataframe are in every row of the csv\n",
    "    nsearches = df['num_searches'].iloc[0]\n",
    "    nrepeats = df['repeats'].iloc[0]\n",
    "    npoints = df['npoints'].iloc[0]\n",
    "    add_execution_details(cloud, dataset, nsearches, nrepeats, npoints, fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of neighSearch runtimes for Lille_0 across all radii kernels benchmarked and all octree types\n",
    "fig = octree_runtime_comparison(\"Lille_0\", \"Paris_Lille\", ['neighSearchStruct', 'neighSearch'], 'Neighbor search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of neighSearch runtimes for Lille_0 across all radii kernels benchmarked and all octree types\n",
    "fig = octree_runtime_comparison(\"Lille_0\", \"Paris_Lille\", ['numNeighSearch'], 'Neighbor search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same plots but with warmup times\n",
    "fig = octree_runtime_comparison(\"Lille_0\", \"Paris_Lille\", ['neighSearchStruct', 'neighSearch'], 'Num. of neighbors search', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = octree_runtime_comparison(\"Lille_0\", \"Paris_Lille\", ['numNeighSearch'], 'Num. of neighbors search', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = octree_runtime_comparison(\"Lille_0\", \"Paris_Lille\", ['neighSearchStruct', 'neighSearch'], 'Num. of neighbors search', True, TYPES_INFO_OCTREE_POINT, POINT_COMP_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octree_operations_comparison(cloud, dataset, operations, palette, data_path=ALGO_COMP_DATA_PATH):\n",
    "    df = get_dataset_file(cloud, \"latest\", data_path)\n",
    "    # Filter for the specified operations\n",
    "    df = df[df['operation'].isin(operations)]\n",
    "    \n",
    "    # Get unique radii and kernels\n",
    "    radii = sorted(df['radius'].unique())\n",
    "    kernels = df['kernel'].unique()\n",
    "    \n",
    "    # Create subplot grid with reduced vertical spacing\n",
    "    fig, axes = plt.subplots(len(radii), 1, figsize=(12, 5 + 3 * len(radii)),\n",
    "                           gridspec_kw={'hspace': 0.3})\n",
    "    if len(radii) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Bar spacing parameters\n",
    "    bar_width = 0.35 / len(operations)  # Dynamically adjust width based on operation count\n",
    "    group_width = bar_width * len(operations)\n",
    "    group_gap = 0.10\n",
    "    \n",
    "    legend_handles, legend_labels = [], []\n",
    "    \n",
    "    # First loop through each radius\n",
    "    for radius_idx, radius in enumerate(radii):\n",
    "        ax = axes[radius_idx]\n",
    "        radius_data = df[df['radius'] == radius]\n",
    "        \n",
    "        # Now iterate through kernels\n",
    "        kernel_labels = []\n",
    "        for i, kernel in enumerate(kernels):\n",
    "            kernel_data = radius_data[radius_data['kernel'] == kernel]\n",
    "            if kernel_data.empty:\n",
    "                kernel_labels.append(f'{kernel} kernel\\nNo data available')\n",
    "                continue\n",
    "            \n",
    "            avg_total = kernel_data['avg_result_size'].iloc[0]\n",
    "            kernel_labels.append(f'{kernel} kernel\\nAvg. points found: {avg_total:,.0f}')\n",
    "            \n",
    "            for j, operation in enumerate(operations):\n",
    "                op_data = kernel_data[kernel_data[\"operation\"] == operation]\n",
    "                if op_data.empty:\n",
    "                    print(f\"Warning: No data found for operation {operation} in radius {radius} and kernel {kernel}\")\n",
    "                    continue\n",
    "                \n",
    "                means = op_data['mean'].values\n",
    "                stdevs = op_data['stdev'].values\n",
    "                x_pos = i * (group_width + group_gap) + j * bar_width\n",
    "                \n",
    "                # Get color from palette, with fallback for extra operations\n",
    "                color_idx = j % len(palette)\n",
    "                bar = ax.bar(x_pos, means[0], bar_width,\n",
    "                            color=palette[color_idx])\n",
    "                ax.errorbar(x_pos, means[0], stdevs[0],\n",
    "                           color='gray', capsize=3, capthick=1,\n",
    "                           fmt='none', elinewidth=1)\n",
    "                \n",
    "                if radius_idx == 0 and operation not in legend_labels:\n",
    "                    legend_handles.append(bar)\n",
    "                    legend_labels.append(operation)\n",
    "        \n",
    "        # Set kernel labels\n",
    "        kernel_group_centers = [i * (group_width + group_gap) + group_width/2 - bar_width/2 for i in range(len(kernels))]\n",
    "        ax.set_xticks(kernel_group_centers)\n",
    "        ax.set_xticklabels(kernel_labels)\n",
    "        \n",
    "        ax.text(0.04, 0.96, f'Radius = {radius}',\n",
    "               transform=ax.transAxes,\n",
    "               fontsize=12, fontweight='bold',\n",
    "               va='top', ha='left')\n",
    "        \n",
    "        ax.set_ylabel(f\"Execution time {'(ms)' if TIMES_IN_MS else '(seconds)'}\")\n",
    "    \n",
    "    # Create a descriptive title for multiple operations\n",
    "    title = \" vs \".join(operations)\n",
    "    subtitle = \"Performance comparison between different Linear Octree search algorithms\"\n",
    "    \n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Operation performed\", fig)\n",
    "    add_title_subtitle(title, subtitle, fig)\n",
    "    \n",
    "    # The number of searches, repeats and points in the dataframe are in every row of the csv\n",
    "    nsearches = df['num_searches'].iloc[0]\n",
    "    nrepeats = df['repeats'].iloc[0]\n",
    "    npoints = df['npoints'].iloc[0]\n",
    "    add_execution_details(cloud, dataset, nsearches, nrepeats, npoints, fig)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_impl_palette = [\"#1984c5\", \"#22a7f0\", \"#e14b31\"]\n",
    "fig = octree_operations_comparison(\"Lille_0\", \"Paris_Lille\", ['neighSearchStruct', 'neighSearch', 'neighOldSearch'], search_impl_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_search_impl_palette = [\"#1984c5\", \"#e14b31\"]\n",
    "fig = octree_operations_comparison(\"Lille_0\", \"Paris_Lille\", ['numNeighSearch', 'numNeighOldSearch'], num_search_impl_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_search_comparison(cloud, dataset, kernel=\"Sphere\", data_path=APPROX_SEARCH_DATA_PATH):\n",
    "    # Load data\n",
    "    df = get_dataset_file(cloud, \"latest\", data_path)\n",
    "    # Define operations and their colors\n",
    "    operations = ['neighSearchStruct', 'neighSearchApproxUpper', 'neighSearchApproxLower']\n",
    "    operations_palette = {\n",
    "        'neighSearchStruct': \"#3ca370\",\n",
    "        'neighSearchApproxUpper': '#1984c5',\n",
    "        'neighSearchApproxLower': '#e14b31'\n",
    "    }\n",
    "    \n",
    "    # Filter for the specified operations\n",
    "    df = df[df['operation'].isin(operations)]\n",
    "    # Filter by kernel too\n",
    "    df = df[df['kernel'] == kernel]\n",
    "    # Get unique radii\n",
    "    radii = sorted(df['radius'].unique())\n",
    "    \n",
    "    # Create subplot grid with reduced vertical spacing\n",
    "    fig, axes = plt.subplots(len(radii), 1, figsize=(12, 5 + 3 * len(radii)),\n",
    "                           gridspec_kw={'hspace': 0.3})\n",
    "    if len(radii) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    legend_handles, legend_labels = [], []\n",
    "    \n",
    "    # Process each radius\n",
    "    for radius_idx, radius in enumerate(radii):\n",
    "        ax = axes[radius_idx]\n",
    "        \n",
    "        # Get data for this radius\n",
    "        radius_data = df[df['radius'] == radius].copy()\n",
    "        \n",
    "        # Find baseline (exact search)\n",
    "        baseline_row = radius_data[(radius_data['operation'] == 'neighSearchStruct') & \n",
    "                                 (radius_data['tolerance_percentage'] == 0)]\n",
    "        if baseline_row.empty:\n",
    "            ax.text(0.5, 0.5, f'No exact search data available for radius {radius}',\n",
    "                  transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        \n",
    "        baseline = baseline_row['avg_result_size'].iloc[0]\n",
    "        \n",
    "        # Compute relative points\n",
    "        radius_data['relative_points'] = (radius_data['avg_result_size'] / baseline) * 100\n",
    "        \n",
    "        # Remove approximate searches that equal the exact search\n",
    "        # approx_mask = (radius_data['operation'] != 'neighSearchStruct') & (radius_data['relative_points'] == 100)\n",
    "        # radius_data = radius_data[~approx_mask]\n",
    "        \n",
    "        # Connect points with gray line for each operation within this radius\n",
    "        for op in operations:\n",
    "            op_data = radius_data[radius_data['operation'] == op].sort_values('relative_points')\n",
    "            if not op_data.empty:\n",
    "                ax.plot(op_data['relative_points'], op_data['mean'],\n",
    "                      color='gray', alpha=0.5, linestyle='-')\n",
    "                \n",
    "                # Plot the scatter points\n",
    "                scatter = ax.scatter(op_data['relative_points'], op_data['mean'],\n",
    "                                  color=operations_palette[op], s=80)\n",
    "                \n",
    "                # Add to legend only once\n",
    "                if radius_idx == 0 and op not in legend_labels:\n",
    "                    legend_handles.append(scatter)\n",
    "                    legend_labels.append(op)\n",
    "                \n",
    "                # Annotate points with tolerance percentage\n",
    "                for _, row in op_data.iterrows():\n",
    "                    ax.annotate(f\"{row['tolerance_percentage']}% tol\", \n",
    "                              (row['relative_points'], row['mean']),\n",
    "                              xytext=(5, 5), textcoords='offset points',\n",
    "                              fontsize=8)\n",
    "        \n",
    "        ax.text(0.04, 0.96, f'Radius = {radius}',\n",
    "               transform=ax.transAxes,\n",
    "               fontsize=12, fontweight='bold',\n",
    "               va='top', ha='left')\n",
    "        \n",
    "        y_max = radius_data['mean'].max()\n",
    "        ax.set_ylim(0, y_max * 1.1)  # Increase by 10% the Y limit\n",
    "\n",
    "        ax.set_xlabel(\"Points Found (% of exact search)\")\n",
    "        ax.set_ylabel(f\"Execution time {'(ms)' if TIMES_IN_MS else '(seconds)'}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add overall title and subtitle\n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Search method\", fig)\n",
    "    add_title_subtitle(\"Approximate Search Performance Analysis\",\n",
    "                      f\"Execution time vs. percentage of points found, {kernel} kernel\", fig)\n",
    "    \n",
    "    # Add execution details if available\n",
    "    if not df.empty:\n",
    "        nsearches = df['num_searches'].iloc[0]\n",
    "        nrepeats = df['repeats'].iloc[0]\n",
    "        npoints = df['npoints'].iloc[0]\n",
    "        add_execution_details(cloud, dataset, nsearches, nrepeats, npoints, fig)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_data_path = os.path.join(BASE_DATA_PATH, \"approx_search\")\n",
    "fig = approximate_search_comparison(\"Lille_0\", \"Paris_Lille\", \"Cube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple datasets\n",
    "CLOUDS_DATASETS = {\"Lille_0\": \"Paris_Lille\", \n",
    "                    \"Lille_11\": \"Paris_Lille\",\n",
    "                    \"Paris_Luxembourg_6\": \"Paris_Lille\",\n",
    "                    \"5110_54320\": \"Dales_LAS\",\n",
    "                    \"5135_54435\": \"Dales_LAS\"\n",
    "                }\n",
    "RADII = {0.5, 1.0, 2.5, 5.0}\n",
    "CLOUDS_DATASETS_HIGH_DENSITY = {\n",
    "                    # \"bildstein_station1_xyz_intensity_rgb\": \"Semantic3D\",\n",
    "                    # \"sg27_station8_intensity_rgb\": \"Semantic3D\",\n",
    "                    # \"Speulderbos_2017_TLS\": \"Speulderbos\"\n",
    "                }\n",
    "RADII_HIGH_DENSITY = {0.05, 0.1, 0.25, 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea 3.\n",
    "def multiple_dfs_runtimes(clouds_datasets, kernel, radii, operations, operation_name, types_info=TYPES_INFO_OCTREE_ENCODER):\n",
    "    dfs = read_multiple_datasets(clouds_datasets, OCTREE_COMP_DATA_PATH)\n",
    "    fig, axes = plt.subplots(len(radii), len(dfs), \n",
    "                              figsize=(max(15, len(dfs) * 2.5), 3 + len(radii) * 2.5),\n",
    "                              gridspec_kw={'wspace': 0.7, 'hspace': 0.2})\n",
    "\n",
    "    # Ensure axes are iterable for single-row or single-column cases\n",
    "    if len(radii) == 1:\n",
    "        axes = [axes]\n",
    "    if len(dfs) == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "\n",
    "    # Define bar width and spacing\n",
    "    bar_width = 0.02\n",
    "\n",
    "    legend_handles, legend_labels = [], []\n",
    "\n",
    "    # Iterate over radii and datasets\n",
    "    for radius_idx, radius in enumerate(radii):\n",
    "        for df_idx, (df_name, df) in enumerate(dfs.items()):\n",
    "            ax = axes[radius_idx][df_idx]\n",
    "\n",
    "            # Filter data for the current kernel, radius, and operation\n",
    "            radius_data = df[(df['kernel'] == kernel) & (df['radius'] == radius) & (df['operation'].isin(operations))]\n",
    "\n",
    "            if radius_data.empty:\n",
    "                ax.text(0.5, 0.5, f\"No data available\\n{df_name}\\nRadius = {radius}\",\n",
    "                        transform=ax.transAxes, ha='center', va='center', fontsize=8, color='red')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            \n",
    "            # Iterate through octree implementations\n",
    "            for j, (_, params) in enumerate(types_info[\"available_types\"].iterrows()):\n",
    "                key = tuple(params[col] for col in types_info[\"type_parameters\"])\n",
    "                octree_data = radius_data[\n",
    "                    (radius_data[types_info[\"type_parameters\"]] == pd.Series(key, index=types_info[\"type_parameters\"])).all(axis=1)\n",
    "                ]\n",
    "\n",
    "                if octree_data.empty:\n",
    "                    continue\n",
    "\n",
    "                means = octree_data['mean'].values\n",
    "                stdevs = octree_data['stdev'].values\n",
    "                x_pos = j * bar_width\n",
    "                bar = ax.bar(x_pos, means[0], bar_width, color=types_info[\"palette\"][key])\n",
    "                ax.errorbar(x_pos, means[0], stdevs[0],\n",
    "                            color='gray', capsize=2, capthick=1,\n",
    "                            fmt='none', elinewidth=1)\n",
    "\n",
    "                formatted_label = \", \".join(f\"{value}\" for param, value in zip(types_info[\"type_parameters\"], key))\n",
    "                if (radius_idx == 0) and (df_idx == 0) and (formatted_label not in legend_labels):\n",
    "                    legend_handles.append(bar)\n",
    "                    legend_labels.append(formatted_label)\n",
    "                ax.text(0.04, 0.96, f'r = {radius}', \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=9, va='top', ha='left')\n",
    "            # Remove x-ticks\n",
    "            ax.set_xticks([])\n",
    "            ax.set_ylabel(f\"Execution time {'(ms)' if TIMES_IN_MS else '(seconds)'}\", fontsize = 10)\n",
    "\n",
    "            avg_total = radius_data['avg_result_size'].iloc[0]\n",
    "            ax.text(0.5, -0.1, f\"Avg. points = {avg_total:,.0f}\", \n",
    "                    transform=ax.transAxes, ha='center', va='center', fontsize=8)\n",
    "            \n",
    "    # Adjust subplot spacing\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    # Add legend and titles\n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Octree type\", fig)\n",
    "\n",
    "    add_title_subtitle(\n",
    "        f\"{operation_name} performance analysis\",\n",
    "        f\"Performance across multiple datasets for {operation_name} using {kernel} kernel\\n\",\n",
    "        fig\n",
    "    )\n",
    "\n",
    "    # Assuming the first dataframe has consistent metadata\n",
    "    nsearches = dfs[next(iter(dfs))]['num_searches'].iloc[0]\n",
    "    nrepeats = dfs[next(iter(dfs))]['repeats'].iloc[0]\n",
    "    add_execution_details_multiple_datasets(dfs.keys(), nsearches, nrepeats, fig, h_ex=0.93)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multiple_dfs_runtimes(\n",
    "    CLOUDS_DATASETS, \n",
    "    kernel=\"Sphere\", \n",
    "    radii=RADII, \n",
    "    operations=['neighSearchStruct', 'neighSearch'], \n",
    "    operation_name='Neighbor Search'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(CLOUDS_DATASETS_HIGH_DENSITY):\n",
    "    fig = multiple_dfs_runtimes(\n",
    "        CLOUDS_DATASETS_HIGH_DENSITY, \n",
    "        kernel=\"Sphere\", \n",
    "        radii=RADII_HIGH_DENSITY, \n",
    "        operations=['neighSearchStruct', 'neighSearch'], \n",
    "        operation_name='Neighbor Search'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def multiple_dfs_speedups(clouds_datasets, kernel, radii, operations, operation_name, types_info=TYPES_INFO_OCTREE_ENCODER):\n",
    "    dfs = read_multiple_datasets(clouds_datasets, OCTREE_COMP_DATA_PATH)\n",
    "    fig, axes = plt.subplots(len(radii), len(dfs), \n",
    "                              figsize=(max(12, len(dfs) * 3), len(radii) * 2.5 + 2),\n",
    "                              gridspec_kw={'wspace': 0.7, 'hspace': 0.2})\n",
    "\n",
    "    # Ensure axes are iterable for single-row or single-column cases\n",
    "    if len(radii) == 1:\n",
    "        axes = [axes]\n",
    "    if len(dfs) == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "\n",
    "    # Define bar width and spacing\n",
    "    bar_width = 0.02\n",
    "\n",
    "    legend_handles, legend_labels = [], []\n",
    "\n",
    "    # Iterate over radii and datasets\n",
    "    for radius_idx, radius in enumerate(radii):\n",
    "        for df_idx, (df_name, df) in enumerate(dfs.items()):\n",
    "            ax = axes[radius_idx][df_idx]\n",
    "\n",
    "            # Add the dataset name as the column header on the first row\n",
    "            if radius_idx == 0:\n",
    "                ax.set_title(df_name, fontsize=10)\n",
    "\n",
    "            # Filter data for the current kernel, radius, and operation\n",
    "            radius_data = df[(df['kernel'] == kernel) & \n",
    "                             (df['radius'] == radius) & \n",
    "                             (df['operation'].isin(operations))]\n",
    "            if radius_data.empty:\n",
    "                ax.text(0.5, 0.5, f\"No data\\n{df_name}\\nRadius = {radius}\",\n",
    "                        transform=ax.transAxes, ha='center', va='center', fontsize=8, color='red')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # Kernel label\n",
    "            avg_total = radius_data['avg_result_size'].iloc[0]\n",
    "            \n",
    "            # Add radius label in top-left of each subplot\n",
    "            ax.text(0.05, 0.95, f'r = {radius}', \n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=9, va='top', ha='left')\n",
    "\n",
    "            # Find base execution time for \"Pointer\" octree and \"Unencoded\" encoder\n",
    "            base_data = radius_data[(radius_data['octree'] == \"Octree\") & (radius_data['encoder'] == \"Unencoded\")]\n",
    "            base_time = base_data['mean'].iloc[0]  # Base execution time for the reference combination\n",
    "\n",
    "            # Collect speedup values for setting y-axis limits later\n",
    "            speedups = []\n",
    "\n",
    "            # Iterate through octree implementations (reversed to show increasing speedups)\n",
    "            rev_list = list(types_info[\"available_types\"].iterrows())[::-1]\n",
    "            for j, (_, params) in enumerate(rev_list):\n",
    "                key = tuple(params[col] for col in types_info[\"type_parameters\"])\n",
    "                # Skip the baseline (Pointer, Unencoded) combination\n",
    "                if key == (\"Pointer\", \"Unencoded\"):\n",
    "                    continue\n",
    "                # Filter for the current octree type\n",
    "                octree_data = radius_data[\n",
    "                    (radius_data[types_info[\"type_parameters\"]] == pd.Series(key, index=types_info[\"type_parameters\"])).all(axis=1)\n",
    "                ]\n",
    "\n",
    "                if octree_data.empty:\n",
    "                    continue\n",
    "\n",
    "                means = octree_data['mean'].values\n",
    "                # Calculate the speedup ratio (e.g., 2x means base_time / current_time == 2)\n",
    "                speedup = base_time / means[0]\n",
    "                speedups.append(speedup)\n",
    "\n",
    "                x_pos = j * bar_width\n",
    "                bar = ax.bar(x_pos, speedup, bar_width, color=types_info[\"palette\"][key])\n",
    "\n",
    "                formatted_label = \", \".join(f\"{value}\" for param, value in zip(types_info[\"type_parameters\"], key))\n",
    "                if (radius_idx == 0) and (df_idx == 0) and (formatted_label not in legend_labels):\n",
    "                    legend_handles.append(bar)\n",
    "                    legend_labels.append(formatted_label)\n",
    "\n",
    "            # Set y-axis: start at 1 and set ticks in integer steps formatted as \"1x, 2x, 3x, ...\"\n",
    "            if speedups:\n",
    "                max_speedup = max(speedups + [1])  # Ensure the lower bound is at least 1\n",
    "                y_max = math.ceil(max_speedup)\n",
    "                ax.set_ylim(0, y_max)\n",
    "                ticks = np.arange(0, y_max + 1)\n",
    "                ax.set_yticks(ticks)\n",
    "                ax.set_yticklabels([f\"{int(t)}x\" for t in ticks])\n",
    "            else:\n",
    "                # Default axis if no bars were drawn\n",
    "                ax.set_ylim(0, 2)\n",
    "                ax.set_yticks([0, 1, 2])\n",
    "                ax.set_yticklabels([\"0x\", \"1x\", \"2x\"])\n",
    "\n",
    "            # Remove x-ticks and update y-axis label\n",
    "            ax.set_xticks([])\n",
    "            ax.text(0.5, -0.1, f\"Avg. points = {avg_total:,.0f}\", \n",
    "                    transform=ax.transAxes, ha='center', va='center', fontsize=8)\n",
    "\n",
    "    # Adjust subplot spacing\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3, bottom=0.15)\n",
    "    \n",
    "    # Add legend and titles\n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Octree type\", fig)\n",
    "\n",
    "    add_title_subtitle(\n",
    "        f\"{operation_name} performance analysis\",\n",
    "        f\"Speedup (with respect to baseline Pointer-based octree) using {kernel} kernel\",\n",
    "        fig\n",
    "    )\n",
    "\n",
    "    # Assuming the first dataframe has consistent metadata\n",
    "    nsearches = dfs[next(iter(dfs))]['num_searches'].iloc[0]\n",
    "    nrepeats = dfs[next(iter(dfs))]['repeats'].iloc[0]\n",
    "    add_execution_details_multiple_datasets(dfs.keys(), nsearches, nrepeats, fig, 0.93)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multiple_dfs_speedups(\n",
    "    CLOUDS_DATASETS, \n",
    "    kernel=\"Sphere\", \n",
    "    radii=RADII, \n",
    "    operations=['neighSearchStruct', 'neighSearch'], \n",
    "    operation_name='Neighbor Search'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(CLOUDS_DATASETS_HIGH_DENSITY):\n",
    "    fig = multiple_dfs_speedups(\n",
    "        CLOUDS_DATASETS_HIGH_DENSITY, \n",
    "        kernel=\"Sphere\", \n",
    "        radii=RADII_HIGH_DENSITY, \n",
    "        operations=['neighSearchStruct', 'neighSearch'], \n",
    "        operation_name='Neighbor Search'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to save a lot of plots\n",
    "ALL_CLOUDS = CLOUDS_DATASETS.copy()\n",
    "ALL_CLOUDS.update(CLOUDS_DATASETS_HIGH_DENSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def plot_avg_result_sizes_log(clouds_datasets, kernel, operations, operation_name, types_info=TYPES_INFO_OCTREE_ENCODER):\n",
    "    dfs = read_multiple_datasets(clouds_datasets, OCTREE_COMP_DATA_PATH)\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    legend_handles, legend_labels = [], []\n",
    "    \n",
    "    for j, (_, params) in enumerate(types_info[\"available_types\"].iterrows()):\n",
    "        key = tuple(params[col] for col in types_info[\"type_parameters\"])\n",
    "        avg_sizes, runtimes = [], []\n",
    "        \n",
    "        for df_name, df in dfs.items():\n",
    "            filtered_df = df[(df['kernel'] == kernel) & (df['operation'].isin(operations))]\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "            octree_data = filtered_df[\n",
    "                (filtered_df[types_info[\"type_parameters\"]] == pd.Series(key, index=types_info[\"type_parameters\"])).all(axis=1)\n",
    "            ]\n",
    "            if octree_data.empty:\n",
    "                continue\n",
    "            avg_sizes.extend(octree_data['avg_result_size'].tolist())\n",
    "            runtimes.extend(octree_data['mean'].tolist())\n",
    "\n",
    "        if avg_sizes and runtimes:\n",
    "            scatter = ax.scatter(avg_sizes, runtimes, color=types_info[\"palette\"][key], s=20)\n",
    "            legend_handles.append(scatter)\n",
    "            legend_labels.append(\", \".join(f\"{value}\" for param, value in zip(types_info[\"type_parameters\"], key)))\n",
    "            # linear regression line\n",
    "            # slope, intercept, r_value, p_value, std_err = stats.linregress(np.log(avg_sizes), np.log(runtimes))\n",
    "            # regression_line = np.exp(intercept + slope * np.log(np.array(avg_sizes)))\n",
    "            # ax.plot(avg_sizes, regression_line, color=types_info[\"palette\"][key], linestyle='dashed', linewidth=1)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Average Result Size\")\n",
    "    ax.set_ylabel(f\"Execution time {'(ms)' if TIMES_IN_MS else '(seconds)'}\")\n",
    "        \n",
    "    # Add legend and titles\n",
    "    add_octree_types_legend(legend_handles, legend_labels, \"Octree type\", fig)\n",
    "\n",
    "    add_title_subtitle(\n",
    "        f\"{operation_name} performance analysis\",\n",
    "        f\"Average point founds in search vs runtime (log-log plot), using {kernel} kernel\",\n",
    "        fig\n",
    "    )\n",
    "\n",
    "    # Assuming the first dataframe has consistent metadata\n",
    "    nsearches = dfs[next(iter(dfs))]['num_searches'].iloc[0]\n",
    "    nrepeats = dfs[next(iter(dfs))]['repeats'].iloc[0]\n",
    "    add_execution_details_multiple_datasets(dfs.keys(), nsearches, nrepeats, fig, 0.93)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_avg_result_sizes_log(ALL_CLOUDS, \"Sphere\", [\"neighSearchStruct\", \"neighSearch\"], \"Neighbors search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_avg_result_sizes_log(ALL_CLOUDS, \"Sphere\", [\"numNeighSearch\"], \"Num. of neighbors search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def octree_parallelization(cloud, dataset, openmp_schedule, octree, data_path, annotated=False):\n",
    "    df = get_dataset_file(cloud, \"latest\", data_path)\n",
    "    df = df[(df[\"openmp_schedule\"] == openmp_schedule) & (df[\"octree\"] == octree)][[\"num_searches\", \"repeats\", \"npoints\", \"radius\", \"mean\", \"openmp_threads\"]]\n",
    "    # Extract ntreads=1 baseline\n",
    "    baseline = df[df[\"openmp_threads\"] == 1].set_index(\"radius\")[\"mean\"]\n",
    "    # Merge it on the df\n",
    "    df = df.merge(baseline.rename(\"T1\"), on=\"radius\")\n",
    "    # Compute the efficiency as (time 1 thread) / (time n threads * n)\n",
    "    df[\"efficiency\"] = df[\"T1\"] / (df[\"openmp_threads\"] * df[\"mean\"])\n",
    "    # Pivot and get the efficiency matrix\n",
    "    efficiency_matrix = df.pivot(index=\"radius\", columns=\"openmp_threads\", values=\"efficiency\")\n",
    "    figsize = (24, 4) if annotated else (12, 4)\n",
    "    fig, ax = plt.subplots(figsize=figsize, gridspec_kw={'top': 0.75})\n",
    "    sns.heatmap(efficiency_matrix, cmap=\"mako\", annot=annotated, fmt=\".2f\", linewidths=0, \n",
    "                vmin=0, vmax=1, \n",
    "                cbar_kws={'label': 'Efficiency', 'shrink': 0.8}, # Add the shrink parameter\n",
    "                ax=ax)    \n",
    "    plt.subplots_adjust(bottom=0.05)\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(\"Number of Threads\")\n",
    "    ax.set_ylabel(\"Search radius\")\n",
    "\n",
    "    add_title_subtitle(r\"Parallelization Efficiency\",\n",
    "                       f\"{'Pointer based Octree' if octree == 'Octree' else 'Linear octree'} with {openmp_schedule} schedule\", \n",
    "                       fig, 0.9, 0.82)\n",
    "    nsearches = df['num_searches'].iloc[0]\n",
    "    nrepeats = df['repeats'].iloc[0]\n",
    "    npoints = df['npoints'].iloc[0]\n",
    "    add_execution_details(cloud, dataset, nsearches, nrepeats, npoints, fig, 0.9, 0.45)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_data_path = os.path.join(BASE_DATA_PATH, \"parallel_full\")\n",
    "\n",
    "fig1 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"static\", \"Octree\", parallel_data_path, True)\n",
    "fig2 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"dynamic\", \"Octree\", parallel_data_path, True)\n",
    "fig3 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"guided\", \"Octree\", parallel_data_path, True)\n",
    "fig4 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"static\", \"LinearOctree\", parallel_data_path, True)\n",
    "fig5 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"dynamic\", \"LinearOctree\", parallel_data_path, True)\n",
    "fig6 = octree_parallelization(\"Lille_0\", \"Paris_Lille\", \"guided\", \"LinearOctree\", parallel_data_path, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schedules = [\"static\", \"dynamic\", \"guided\"]\n",
    "octrees = [\"Octree\", \"LinearOctree\"]\n",
    "for octree in octrees:\n",
    "    for schedule in schedules:\n",
    "        output_fig(octree_parallelization(\"Lille_0\", \"Paris_Lille\", schedule, octree, parallel_data_path, True), f\"parallel_{schedule}_{octree.lower()}\", \"Paris_Lille\", \"Lille_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Octree comparisons\n",
    "assert(True)\n",
    "for cloud, dataset in ALL_CLOUDS.items():\n",
    "        for warmup in [False, True]:\n",
    "            output_fig(octree_runtime_comparison(cloud, dataset, ['neighSearchStruct', 'neighSearch'], 'Neighbors search', warmup), \"octree_comp_neigh\", dataset, cloud)\n",
    "            output_fig(octree_runtime_comparison(cloud, dataset, ['numNeighSearch'], 'Num. of neighbors search', warmup), \"octree_comp_numneigh\", dataset, cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point type comparisons\n",
    "for cloud, dataset in ALL_CLOUDS.items():\n",
    "    output_fig(octree_runtime_comparison(cloud, dataset, ['neighSearchStruct', 'neighSearch'], 'Num. of neighbors search', False,\n",
    "                            TYPES_INFO_OCTREE_POINT, POINT_COMP_DATA_PATH), \"point_comp_neigh\", dataset, cloud)\n",
    "    output_fig(octree_runtime_comparison(cloud, dataset, ['numNeighSearch'], 'Num. of neighbors search', False,\n",
    "                            TYPES_INFO_OCTREE_POINT, POINT_COMP_DATA_PATH), \"point_comp_numneigh\", dataset, cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search impl. comparisons\n",
    "for cloud, dataset in ALL_CLOUDS.items():\n",
    "    output_fig(octree_operations_comparison(cloud, dataset, ['neighSearchStruct', 'neighSearch', 'neighOldSearch'], search_impl_palette), \"impl_comp_neigh\", dataset, cloud)\n",
    "    output_fig(octree_operations_comparison(cloud, dataset, ['numNeighSearch', 'numNeighOldSearch'], num_search_impl_palette), \"impl_comp_numneigh\", dataset, cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate searches\n",
    "for cloud, dataset in ALL_CLOUDS.items():\n",
    "    for kernel in [\"Sphere\", \"Cube\"]:\n",
    "        output_fig(approximate_search_comparison(cloud, dataset, kernel), f\"approx_searches_{kernel.lower()}\", dataset, cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple dataframes comparisons\n",
    "# Could also output the regular ones but I think its enough with the speedup ones\n",
    "for kernel in [\"Sphere\", \"Cube\"]:\n",
    "    output_fig(multiple_dfs_speedups(CLOUDS_DATASETS, kernel, RADII, operations=['neighSearchStruct','neighSearch'], operation_name='Neighbors Search'), \n",
    "                f\"speedup_neigh_search_{kernel.lower()}\")\n",
    "    output_fig(multiple_dfs_speedups(CLOUDS_DATASETS, kernel, RADII, operations=['numNeighSearch'], operation_name='Num. of Neighbors Search'), \n",
    "                f\"speedup_num_neigh_search_{kernel.lower()}\")\n",
    "\n",
    "for kernel in [\"Sphere\", \"Cube\"]:\n",
    "    output_fig(multiple_dfs_speedups(CLOUDS_DATASETS_HIGH_DENSITY, kernel, RADII_HIGH_DENSITY, operations=['neighSearchStruct','neighSearch'], operation_name='Neighbors Search'), \n",
    "                f\"speedup_high_density_neigh_{kernel.lower()}\")\n",
    "    output_fig(multiple_dfs_speedups(CLOUDS_DATASETS_HIGH_DENSITY, kernel, RADII_HIGH_DENSITY, operations=['numNeighSearch'], operation_name='Num. of Neighbors Search'), \n",
    "                f\"speedup_high_density_numneigh_{kernel.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg result sizes vs runtime\n",
    "for kernel in [\"Sphere\", \"Cube\"]:\n",
    "    output_fig(plot_avg_result_sizes_log(ALL_CLOUDS, kernel, [\"neighSearchStruct\", \"neighSearch\"], \"Neighbors search\"),\n",
    "               f\"avg_result_size_runtime_neigh_{kernel.lower()}\")\n",
    "    output_fig(plot_avg_result_sizes_log(ALL_CLOUDS, kernel, [\"numNeighSearch\"], \"Num. of Neighbors Search\"),\n",
    "               f\"avg_result_size_runtime_numneigh_{kernel.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Octree parallelization\n",
    "for cloud, dataset in CLOUDS_DATASETS.items():\n",
    "    for schedule in [\"static\", \"dynamic\", \"guided\"]:\n",
    "        for octree in [\"Octree\", \"LinearOctree\"]:\n",
    "            output_fig(octree_parallelization(cloud, dataset, schedule, octree, parallel_data_path, True), f\"parallel_{schedule}_{octree.lower()}\", dataset, cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
